{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "- INIT MODEL WITH CLASSIFIER MODEL WEIGHTS ✅\n",
    "- FINE TUNE ✅\n",
    "- ADD MORE AUGMENTATION (ZOOM ✅, CROP ON DIFF BACK ❌) ✅❌ \n",
    "- PREDICT WITH TTA \n",
    "- DISABLE BATCHNORM, BATCH-RENORM, USE ABN https://github.com/mapillary/inplace_abn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../fastai/old\")\n",
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a detection/segmentation model for images with ships\n",
    "\n",
    "**idea : rather than fine tuning imagenet for detection/segmentation fine tune with the fine tuned model for ship classifier** \n",
    "\n",
    "- train_seg_lbs : images in train_all folder with segmentation\n",
    "- test_seg_lbs : images in test_all folder with segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../DATA/airbus-ship/\")\n",
    "files = list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Recover segmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = ! ls {path}/\"train\"\n",
    "test_images = ! ls {path}/\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_segmentation = pd.read_csv(path/\"train_ship_segmentations.csv\")\n",
    "test_segmentation = pd.read_csv(path/\"test_ship_segmentations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_segmentation = pd.concat([train_segmentation, test_segmentation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_segmentation_df = all_segmentation[all_segmentation.ImageId.isin(train_images)]\n",
    "test_segmentation_df = all_segmentation[all_segmentation.ImageId.isin(test_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_segmentation_df.shape, test_segmentation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove images without ship\n",
    "trn_segmentation_df = trn_segmentation_df[~trn_segmentation_df.EncodedPixels.isna()]\n",
    "test_segmentation_df = test_segmentation_df[~test_segmentation_df.EncodedPixels.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(path/\"segmentation\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_segmentation_df.reset_index(drop=True).to_csv(path/\"segmentation/trn_segmentation.csv\", index=False)\n",
    "test_segmentation_df.reset_index(drop=True).to_csv(path/\"segmentation/test_segmentation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize segmentation data\n",
    "\n",
    "We exclude images without ship to deal with imbalance and focus on learning ship segmentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_seg_lbs = pd.read_csv(path/\"segmentation/trn_segmentation.csv\")\n",
    "test_seg_lbs = pd.read_csv(path/\"segmentation/test_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"# of train segmentation images: {train_seg_lbs.ImageId.nunique()}\")\n",
    "print(f\"# of test segmentation images: {test_seg_lbs.ImageId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"# of train segmentation labels/ships: {len(train_seg_lbs.ImageId)}\")\n",
    "print(f\"# of test segmentation labels/ships: {len(test_seg_lbs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rle import rle_decode, rle_encode\n",
    "from seg_plots import show_img_masks, plot_segmentation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_segmentation_df(train_seg_lbs, path/'train', n=10, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save all masks \n",
    "\n",
    "Having rle_decode inside get_y is very expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import as_completed\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "\n",
    "def run_multi_progess(function, args_list, is_thread=True, **kwargs):\n",
    "    # kwargs = {'unit': 'files','unit_scale': True, 'leave': True}\n",
    "    if is_thread: executor = ThreadPoolExecutor(8)\n",
    "    else: executor = ProcessPoolExecutor(4)\n",
    "    with executor as e:\n",
    "        futures = [e.submit(function, arg) for arg in args_list]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), **kwargs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_unique_img_ids = train_seg_lbs.ImageId.unique()\n",
    "test_unique_img_ids = test_seg_lbs.ImageId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(path/'segmentation/train_masks', exist_ok=True)\n",
    "os.makedirs(path/'segmentation/test_masks', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_unique_img_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_train_mask(img_id):\n",
    "    rles = train_seg_lbs[train_seg_lbs.ImageId == img_id]['EncodedPixels'].values\n",
    "    masks = sum([rle_decode(rle, (768, 768)) for rle in rles])\n",
    "    np.save(str(path/'segmentation/train_masks'/img_id), masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_test_mask(img_id):\n",
    "    rles = test_seg_lbs[test_seg_lbs.ImageId == img_id]['EncodedPixels'].values\n",
    "    masks = sum([rle_decode(rle, (768, 768)) for rle in rles])\n",
    "    np.save(str(path/'segmentation/test_masks'/img_id), masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_multi_progess(save_train_mask, trn_unique_img_ids, unit=' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_multi_progess(save_test_mask, test_unique_img_ids, unit=' images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic unet segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.models.unet import *\n",
    "from fastai.dataset import *\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_seg_lbs = pd.read_csv(path/\"segmentation/trn_segmentation.csv\")\n",
    "test_seg_lbs = pd.read_csv(path/\"segmentation/test_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_img_ids = train_seg_lbs.ImageId.unique()\n",
    "trn_fnames, val_fnames = train_test_split(unique_img_ids, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fnames = test_seg_lbs.ImageId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_X = [f\"train/{fname}\" for fname in trn_fnames]\n",
    "TRN_Y = [f\"segmentation/train_masks/{fname}.npy\" for fname in trn_fnames]\n",
    "\n",
    "VAL_X = [f\"train/{fname}\" for fname in val_fnames]\n",
    "VAL_Y = [f\"segmentation/train_masks/{fname}.npy\" for fname in val_fnames]\n",
    "\n",
    "TEST_X = [f\"test/{fname}\" for fname in test_fnames]\n",
    "TEST_Y = [f\"segmentation/test_masks/{fname}.npy\" for fname in test_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_fnames = list((path/\"test_v2\").glob(\"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUB_X = [f\"test_v2/{fname.name}\" for fname in test_sub_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUB_X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(TRN_X), len(VAL_X), len(TEST_X), len(TEST_SUB_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_Y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(path/TEST_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check masks\n",
    "\n",
    "- Some masks are not separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "fig, axes = plt.subplots(nrows, 10, figsize=(nrows*10, 10))\n",
    "for i, ax in enumerate(axes.flatten()): \n",
    "    fname = np.random.permutation(VAL_Y)[i]\n",
    "    ax.imshow(np.load(path/fname))\n",
    "    ax.set_title(fname.split(\"/\")[-1])\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilesEncodedDataset(BaseDataset):\n",
    "    def __init__(self, fnames, fnames2, transform, path):\n",
    "        self.fnames = fnames\n",
    "        self.fnames2 = fnames2\n",
    "        self.path = path\n",
    "        super().__init__(transform)\n",
    "    \n",
    "    def get_sz(self): return self.transform.sz\n",
    "    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_y(self, i): \n",
    "        \n",
    "        mask = np.load(os.path.join(self.path, self.fnames2[i])).astype('float32')\n",
    "        #mask = cv2.resize(mask, (sz, sz)).astype('float32')\n",
    "        #mask = np.round(mask)\n",
    "        return mask\n",
    "        \n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 0\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)\n",
    "\n",
    "    def denorm(self,arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform():\n",
    "    \"\"\" A class that represents a transform.\n",
    "\n",
    "    All other transforms should subclass it.\n",
    "    All subclasses should override\n",
    "    do_transform.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        tfm_y : TfmType\n",
    "            type of transform\n",
    "    \"\"\"\n",
    "    def __init__(self, tfm_y=TfmType.NO):\n",
    "        self.tfm_y=tfm_y\n",
    "        self.store = threading.local()\n",
    "\n",
    "    def set_state(self): pass\n",
    "    def __call__(self, x, y):\n",
    "        self.set_state()\n",
    "        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n",
    "                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n",
    "                else self.transform_coord(x,y))\n",
    "        return x, y\n",
    "\n",
    "    def transform_coord(self, x, y): return self.transform(x),y\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        x = self.do_transform(x,False)\n",
    "        return (x, self.do_transform(y,True)) if y is not None else x\n",
    "\n",
    "    @abstractmethod\n",
    "    def do_transform(self, x, is_y): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if is_y and self.tfm_y != TfmType.PIXEL: return x\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1/(c-1) if c<0 else c+1\n",
    "        x = lighting(x, b, c)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDihedral(CoordTransform):\n",
    "    \"\"\"\n",
    "    Rotates images by random multiples of 90 degrees and/or reflection.\n",
    "    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n",
    "    \"\"\"\n",
    "    def set_state(self):\n",
    "        self.store.rot_times = random.randint(0,3)\n",
    "        self.store.do_flip = random.random()<0.5\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        x = np.rot90(x, self.store.rot_times)\n",
    "        return np.fliplr(x).copy() if self.store.do_flip else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotate an image by deg degrees\n",
    "\n",
    "    Arguments:\n",
    "        deg (float): degree to rotate.\n",
    "    \"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotate(CoordTransform):\n",
    "    \"\"\" Rotates images and (optionally) target y.\n",
    "\n",
    "    Rotating coordinates is treated differently for x and y on this\n",
    "    transform.\n",
    "     Arguments:\n",
    "        deg (float): degree to rotate.\n",
    "        p (float): probability of rotation\n",
    "        mode: type of border\n",
    "        tfm_y (TfmType): type of y transform\n",
    "    \"\"\"\n",
    "    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.deg,self.p = deg,p\n",
    "        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n",
    "            self.modes = (mode,cv2.BORDER_CONSTANT)\n",
    "        else:\n",
    "            self.modes = (mode,mode)\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.rdeg = rand0(self.deg)\n",
    "        self.store.rp = random.random()<self.p\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n",
    "                mode= self.modes[1] if is_y else self.modes[0],\n",
    "                interpolation=cv2.INTER_NEAREST)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_cv(x,z):\n",
    "    \"\"\" Zoom the center of image x by a factor of z+1 while retaining the original image size and proportion. \"\"\"\n",
    "    if z==0: return x\n",
    "    r,c,*_ = x.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n",
    "    return cv2.warpAffine(x,M,(c,r), borderMode=cv2.BORDER_CONSTANT, flags=cv2.WARP_FILL_OUTLIERS+cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomZoom(CoordTransform):\n",
    "    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO, p=1):\n",
    "        super().__init__(tfm_y)\n",
    "        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n",
    "        self.p = p\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n",
    "        self.store.rp = random.random()<self.p\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        if self.store.rp:\n",
    "            x = zoom_cv(x, self.store.zoom)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomRotate(deg=30, p=0.7, tfm_y=TfmType.PIXEL)\n",
    "f = vgg16\n",
    "sz = 768\n",
    "tfms = tfms_from_model(f,\n",
    "                       sz,\n",
    "                       aug_tfms=[\n",
    "                                 RandomRotate(20, p=0.2, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.PIXEL),\n",
    "                           \n",
    "                                 RandomDihedral(tfm_y=TfmType.PIXEL),\n",
    "                           \n",
    "                                 RandomZoom(zoom_max=1.5, zoom_min=0, mode=cv2.BORDER_CONSTANT,\n",
    "                                            tfm_y=TfmType.PIXEL, p=0.2),\n",
    "                                 \n",
    "                                 RandomBlur(blur_strengths=3, probability=0.2, tfm_y=TfmType.NO),\n",
    "                                 \n",
    "                                 RandomLighting(0.05, 0.05)],\n",
    "                       \n",
    "                       tfm_y=TfmType.PIXEL,\n",
    "                       norm_y=False,\n",
    "                       crop_type=CropType.NO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageData.get_ds(FilesEncodedDataset, \n",
    "                           trn=(TRN_X, TRN_Y),\n",
    "                           val=(VAL_X, VAL_Y), tfms=tfms,\n",
    "                           test=(TEST_X, TEST_Y) ,path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageData(path, dataset, bs=16, num_workers=8, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = md.trn_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "*x, y= next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot augmentations\n",
    "i = 1\n",
    "\n",
    "fig_sz = (20, 20)\n",
    "fig, axes = plt.subplots(2, 4, figsize=fig_sz)\n",
    "for ax in np.rollaxis(axes, -1):\n",
    "    x,y = next(iter(md.aug_dl))\n",
    "    img = denorm(x)[i]\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(to_np(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(to_np(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n train: {len(md.trn_ds)}, n val: {len(md.val_ds)}, n test: {len(md.test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load defined model# load  \n",
    "def get_encoder(f, cut):\n",
    "    base_model = (cut_model(f(True), cut))\n",
    "    return nn.Sequential(*base_model)\n",
    "\n",
    "def get_model(f=resnet18, sz=128):\n",
    "    \"\"\"gets dynamic unet model\"\"\"\n",
    "    # cut encoder\n",
    "    cut, cut_lr = model_meta[f]\n",
    "\n",
    "    # define encoder\n",
    "    encoder = get_encoder(f, cut)\n",
    "\n",
    "    # init model\n",
    "    # binary: ship - not ship\n",
    "    m = DynamicUnet(encoder, n_classes=1) \n",
    "\n",
    "    # init upsample on cpu\n",
    "    inp = torch.ones(1, 3, sz, sz)\n",
    "    out = m(V(inp).cpu())\n",
    "\n",
    "    # put model to gpu if desired# put mo \n",
    "    m = m.cuda(0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(logits, target):\n",
    "    logits = torch.sigmoid(logits)\n",
    "    smooth = 1.0\n",
    "\n",
    "    iflat = logits.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, logits, target):\n",
    "        logits = logits.squeeze(1)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        pt = (target)*probas + (1 - target)*(1 - probas)\n",
    "        loss = (-(1 - pt)**gamma)*torch.log(pt)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, logits, target):\n",
    "        logits = logits.squeeze(1)\n",
    "        if not (target.size() == logits.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), logits.size()))\n",
    "\n",
    "        max_val = (-logits).clamp(min=0)\n",
    "        loss = logits - logits * target + max_val + \\\n",
    "            ((-max_val).exp() + (-logits - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logits * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCELoss2D, self).__init__()\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        logits = logits.squeeze(1)\n",
    "        logits = F.sigmoid(logits)\n",
    "        return F.binary_cross_entropy(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleModel():\n",
    "    def __init__(self, model, cut_lr, name='upsample'):\n",
    "        self.model,self.name, self.cut_lr = model, name, cut_lr\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.encoder), [self.cut_lr]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test metric\n",
    "\n",
    "ref: https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from eval_metric import sigmoid, get_gt_masks, create_iou_matrix, f2_IOU, get_pred_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_score(labels, gt_rles, gt):\n",
    "    \"\"\"\n",
    "    return avg thresholded f2 score for single image\n",
    "    labels : labeled image array\n",
    "    gt_rles : array of rles\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        if gt is None: \n",
    "            \"\"\"original image has no instance\"\"\"\n",
    "            return 1\n",
    "        else:\n",
    "            \"\"\"no prediction is made tp = 0\"\"\"\n",
    "            return 0\n",
    "    else:\n",
    "        pred_mask_arrays = get_pred_masks(labels)\n",
    "        gt_mask_arrays = get_gt_masks(gt_rles)\n",
    "        IOU = create_iou_matrix(pred_mask_arrays, gt_mask_arrays)\n",
    "        return f2_IOU(IOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 0 # shift to keep track of file index \n",
    "n_valids = len(md.val_ds) # total # of validation samples\n",
    "fnames = md.val_ds.fnames # validation filenames\n",
    "df = train_seg_lbs\n",
    "\n",
    "def fastai_metric(preds, targs):\n",
    "    global shift\n",
    "    global df\n",
    "    global fnames\n",
    "    global n_valids\n",
    "    \n",
    "    mask_thresh = 0.5 \n",
    "    n_x = len(preds)\n",
    "\n",
    "    scores = [] \n",
    "    preds = (sigmoid(to_np(preds).squeeze(1)) > mask_thresh).astype('uint8')\n",
    "    gts = to_np(targs)\n",
    "    \n",
    "    for i, (gt_i, pred_i) in enumerate(zip(gts, preds)):\n",
    "        fname = fnames[i+shift]\n",
    "        gt_rles = df[df.ImageId == fname.split(\"/\")[-1]]['EncodedPixels'].values\n",
    "        labels = label(pred_i)\n",
    "        scores.append(single_image_score(labels, gt_rles, gt_i))\n",
    "\n",
    "    shift += n_x\n",
    "    if shift == n_valids: shift = 0\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_model = False\n",
    "f = resnet18\n",
    "cut, cut_lr = model_meta[f]\n",
    "model = get_model(f, sz=768)\n",
    "models = UpsampleModel(model, cut_lr)\n",
    "\n",
    "if init_model:\n",
    "    cls_weights = torch.load(path/\"models/resnet34_classification_ft_v2.224.h5\")\n",
    "    state_dict_keys = list(model.encoder.state_dict().keys())\n",
    "    for k in state_dict_keys: model.encoder.state_dict()[k].copy_(cls_weights[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MixedLoss(10, 2)\n",
    "learn.metrics = [fastai_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   fastai_metric                  \n",
      "    0      0.398282   0.383816   0.246809  \n",
      "    1      0.373837   0.312183   0.279532                       \n",
      "    2      0.303733   4.703829   0.267776                       \n",
      "    3      0.329927   0.36759    0.31621                        \n",
      "    4      0.314626   0.256905   0.314863                       \n",
      "    5      0.253966   0.247697   0.330798                       \n",
      "    6      0.238425   0.238802   0.34247                        \n",
      "    7      0.267847   0.221725   0.357736                       \n",
      "    8      0.213951   0.218158   0.356572                       \n",
      "    9      0.22161    0.202039   0.364887                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.20204]), 0.36488680514216265]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(3e-3, n_cycle=1, cycle_len=10, use_clr=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"resnet34_segmentation_v6.768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d39913f838485f8fba412db2e02ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 1044/2148 [18:04<33:12,  1.80s/it, loss=0.375] "
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3e-3, n_cycle=1, cycle_len=10, use_clr=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"resnet34_segmentation_v7.768\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"resnet34_segmentation_v4.768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr = 1e-4\n",
    "lrs = [lr/100, lr/10, lr]\n",
    "learn.fit(lrs, n_cycle=1, cycle_len=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"resnet34_segmentation_v3.768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_plots import plot_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_batch(path,\n",
    "           learn.model.eval(),\n",
    "           learn.data.val_dl,\n",
    "           learn.data.val_ds.fnames,\n",
    "           20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single test preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_plots import show_img_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = learn.predict(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds2 = [sigmoid(pred[0]) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_lbs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fnames = iter(zip(test_preds2, learn.data.test_ds.fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, fname = next(pred_fnames)\n",
    "fname = fname.split(\"/\")[1]    \n",
    "gt_rles = test_seg_lbs[test_seg_lbs.ImageId == fname]['EncodedPixels'].values\n",
    "f2_score = single_image_score(label(pred>0.5), gt_rles, gt_rles)\n",
    "print(f2_score)\n",
    "show_img_masks(open_image(path/f\"test/{fname}\"), pred>0.5, size=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_maps = []\n",
    "for pred, fname in zip(test_preds2, learn.data.test_ds.fnames):\n",
    "    fname = fname.split(\"/\")[1]    \n",
    "    gt_rles = test_seg_lbs[test_seg_lbs.ImageId == fname]['EncodedPixels'].values\n",
    "    f2_score = single_image_score(label(pred > 0.4), gt_rles, gt_rles)\n",
    "    score_maps.append((len(gt_rles), f2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_df = pd.DataFrame(score_maps, columns=[\"n_ships\", \"f2score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_df.groupby(\"n_ships\")[\"f2score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_df[\"f2score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.97*0.52 + 0.38*0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (test_preds2[18]>0.5).astype(np.uint8)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(img, 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, contours, hierarchy = cv2.findContours(img, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = contours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center (x,y), (width, height), angle of rotation \n",
    "rect = cv2.minAreaRect(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_wh = cv2.boxPoints(rect)\n",
    "bbox_wh = np.int0(bbox_wh)\n",
    "angle = rect[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_wh, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.mean(bbox_wh[::2], 0)\n",
    "w = int(np.sqrt(np.mean((bbox_wh[1] - bbox_wh[0])**2)))\n",
    "h = int(np.sqrt(np.mean((bbox_wh[2] - bbox_wh[1])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rbbox(bbox, angle, ax, col='red'):\n",
    "    \"\"\"min row, min col, max row, max col - like np \"\"\"\n",
    "    min_y, min_x, max_y, max_x = bbox\n",
    "    ax.add_patch(Rectangle((min_x, min_y),\n",
    "                           max_x - min_x,\n",
    "                           max_y - min_y,\n",
    "                           angle=angle,\n",
    "                           fill=False,\n",
    "                           color=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rbbox2(x,y,w,h,angle, ax, col='red'):\n",
    "    \"\"\"min row, min col, max row, max col - like np \"\"\"\n",
    "    ax.add_patch(Rectangle((x, y),\n",
    "                           w,\n",
    "                           h,\n",
    "                           angle=angle,\n",
    "                           fill=False,\n",
    "                           color=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.imshow(img)\n",
    "ax.scatter(*np.int0(np.mean(bbox_wh[:2], 0)), c=\"red\")\n",
    "ax.scatter(*np.int0(np.mean(bbox_wh[2:], 0)), c=\"red\")\n",
    "ax.scatter(*np.int0(np.mean(bbox_wh[::2], 0)), c=\"red\")\n",
    "draw_rbbox2(x,y,h,w,angle, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rle import rle_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_preds = pd.read_csv(path/\"classification/test_preds_resnet34_classification_ft_v2_224.csv\", usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.4\n",
    "sum(classification_preds.has_ship_proba > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "has_ship_images = classification_preds[classification_preds.has_ship_proba > thresh][\"ImageId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_fnames = [f\"test_v2/{fname}\" for fname in has_ship_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUB_X = test_seg_fnames\n",
    "TEST_SUB_Y = TRN_Y[:len(test_seg_fnames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TEST_SUB_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomRotate(deg=30, p=0.7, tfm_y=TfmType.PIXEL)\n",
    "f = resnet34\n",
    "sz = 768\n",
    "tfms = tfms_from_model(f,\n",
    "                       sz,\n",
    "                       aug_tfms=[RandomDihedral(tfm_y=TfmType.PIXEL),\n",
    "                                 RandomBlur(),\n",
    "                                 RandomLighting(0.05, 0.05)],\n",
    "                       tfm_y=TfmType.PIXEL,\n",
    "                       norm_y=False,\n",
    "                       crop_type=CropType.NO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageData.get_ds(FilesEncodedDataset, \n",
    "                           trn=(TRN_X, TRN_Y),\n",
    "                           val=(VAL_X, VAL_Y), tfms=tfms,\n",
    "                           test=(TEST_SUB_X, TEST_SUB_Y) ,path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageData(path, dataset, bs=4, num_workers=8, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = resnet34\n",
    "cut, cut_lr = model_meta[f]\n",
    "model = get_model(f, sz=768)\n",
    "models = UpsampleModel(model, cut_lr)\n",
    "\n",
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MixedLoss(10, 2)\n",
    "learn.metrics = [fastai_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"resnet34_segmentation_v3.768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds = learn.predict(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds = [sigmoid(pred.squeeze(0)) for pred in test_preds]\n",
    "test_fnames = [fname.split(\"/\")[1] for fname in learn.data.test_ds.fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds), len(test_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(open_image(path/f\"test_v2/{test_fnames[6]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_preds[6] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_preds = []\n",
    "for fname, pred in zip(test_fnames, test_preds):\n",
    "    labels = label(pred > 0.4)\n",
    "    pred_masks = get_pred_masks(labels, sz=None)\n",
    "    if pred_masks == []:\n",
    "        long_preds.append((fname, None))\n",
    "    else:\n",
    "        for pred_mask in pred_masks:\n",
    "            long_preds.append((fname, rle_encode(pred_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_preds = pd.DataFrame(list(zip(*long_preds))).T.\\\n",
    "                rename(columns={0:\"ImageId\", 1:\"EncodedPixels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segmentation_preds.ImageId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_ship_img_ids = classification_preds[classification_preds.has_ship_proba <=thresh][\"ImageId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ship_df = pd.DataFrame({\"ImageId\": no_ship_img_ids, \"EncodedPixels\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.concat([no_ship_df, segmentation_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(path/\"submission/resnet_34_cls_ft_resnet_34_seg_init.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(path/\"submission/resnet_34_cls_ft_resnet_34_seg_init.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
