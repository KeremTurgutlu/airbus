{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/airbus-ship/\")\n",
    "files = list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../fastai/old\")\n",
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coast preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_val = pd.read_csv(path/\"team_data/classifier_coast1_fold1_predsraw.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193011, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coast_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/rob/data/working/airbus_v2/mosaic_tiles/...</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/rob/data/working/airbus_v2/mosaic_tiles/...</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/rob/data/working/airbus_v2/mosaic_tiles/...</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/rob/data/working/airbus_v2/mosaic_tiles/...</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/rob/data/working/airbus_v2/mosaic_tiles/...</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId         0         1\n",
       "0  /home/rob/data/working/airbus_v2/mosaic_tiles/...  0.998917  0.001083\n",
       "1  /home/rob/data/working/airbus_v2/mosaic_tiles/...  0.999357  0.000643\n",
       "2  /home/rob/data/working/airbus_v2/mosaic_tiles/...  0.999508  0.000492\n",
       "3  /home/rob/data/working/airbus_v2/mosaic_tiles/...  0.999393  0.000607\n",
       "4  /home/rob/data/working/airbus_v2/mosaic_tiles/...  0.999471  0.000529"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coast_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_test = pd.read_csv(path/\"team_data/classifier_coast1_fold2_test_predsraw.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17291, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coast_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002bd58.jpg</td>\n",
       "      <td>9.993741e-01</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015efb6.jpg</td>\n",
       "      <td>9.995047e-01</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00023d5fc.jpg</td>\n",
       "      <td>9.997459e-01</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000367c13.jpg</td>\n",
       "      <td>2.860576e-12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008ca6e9.jpg</td>\n",
       "      <td>9.993843e-01</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId             0         1\n",
       "0  00002bd58.jpg  9.993741e-01  0.000626\n",
       "1  00015efb6.jpg  9.995047e-01  0.000495\n",
       "2  00023d5fc.jpg  9.997459e-01  0.000254\n",
       "3  000367c13.jpg  2.860576e-12  1.000000\n",
       "4  0008ca6e9.jpg  9.993843e-01  0.000616"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coast_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_fold_preds = pd.read_csv(path/\"team_data/stacking/classification_fold_preds.csv\")\n",
    "cls_test_preds = pd.read_csv(path/\"team_data/stacking/classification_test_preds.csv\", usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48912, 2), (15606, 2))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_fold_preds.shape, cls_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_data/mosaic_tiles/2675_003.png</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_data/mosaic_tiles/2612_006.png</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>team_data/mosaic_tiles/0477_120.png</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team_data/mosaic_tiles/2675_002.png</td>\n",
       "      <td>0.000636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team_data/mosaic_tiles/0609_005.png</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 fname     proba\n",
       "0  team_data/mosaic_tiles/2675_003.png  0.000197\n",
       "1  team_data/mosaic_tiles/2612_006.png  0.000581\n",
       "2  team_data/mosaic_tiles/0477_120.png  0.000633\n",
       "3  team_data/mosaic_tiles/2675_002.png  0.000636\n",
       "4  team_data/mosaic_tiles/0609_005.png  0.000676"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_fold_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>has_ship_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c7b10873e.jpg</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563b384e1.jpg</td>\n",
       "      <td>0.154543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b51dde87a.jpg</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>521d1426a.jpg</td>\n",
       "      <td>0.036694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b3ca4cb6.jpg</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  has_ship_proba\n",
       "0  c7b10873e.jpg        0.000571\n",
       "1  563b384e1.jpg        0.154543\n",
       "2  b51dde87a.jpg        0.000012\n",
       "3  521d1426a.jpg        0.036694\n",
       "4  4b3ca4cb6.jpg        0.000053"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4294a02908>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_test_preds.has_ship_proba.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.models.unet import *\n",
    "from fastai.dataset import *\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "\n",
    "fold_csv = f'../data/airbus-ship/team_data/folds/classifierC_hasships_{FOLD}_val_index.csv'\n",
    "\n",
    "\n",
    "MASKS_FN = path/\"team_data/ships_train_tiles_all.csv\"\n",
    "TRAIN_DN = path/\"team_data/mosaic_tiles\"\n",
    "MASKS_DN = path/\"team_data/mosaic_tiles_masks\"\n",
    "\n",
    "def split_by_idx(idxs, *a):\n",
    "    mask = np.zeros(len(a[0]),dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask],o[~mask]) for o in a]\n",
    "    \n",
    "masks_csv = pd.read_csv(MASKS_FN)\n",
    "x_fns = np.array([Path(TRAIN_DN)/f'{o}' for o in masks_csv['fn']]) \n",
    "y_fns = np.array([Path(MASKS_DN)/f'{o}' for o in masks_csv['fn']]) \n",
    "val_idxs = np.loadtxt(fold_csv, dtype=int)\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_fns, y_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_X = trn_x\n",
    "TRN_Y = trn_y\n",
    "\n",
    "VAL_X = val_x\n",
    "VAL_Y = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilesEncodedDataset(BaseDataset):\n",
    "    def __init__(self, fnames, fnames2, transform, path):\n",
    "        self.fnames = fnames\n",
    "        self.fnames2 = fnames2\n",
    "        self.path = path\n",
    "        super().__init__(transform)\n",
    "    \n",
    "    def get_sz(self): return self.transform.sz\n",
    "    def get_x(self, i): return open_image(self.fnames[i])\n",
    "    def get_y(self, i): \n",
    "        \n",
    "        mask = open_image(self.fnames2[i])[:,:,0]\n",
    "        return mask\n",
    "        \n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 0\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)\n",
    "\n",
    "    def denorm(self,arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))\n",
    "    \n",
    "    \n",
    "class Transform():\n",
    "    \"\"\" A class that represents a transform.\n",
    "\n",
    "    All other transforms should subclass it.\n",
    "    All subclasses should override\n",
    "    do_transform.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        tfm_y : TfmType\n",
    "            type of transform\n",
    "    \"\"\"\n",
    "    def __init__(self, tfm_y=TfmType.NO):\n",
    "        self.tfm_y=tfm_y\n",
    "        self.store = threading.local()\n",
    "\n",
    "    def set_state(self): pass\n",
    "    def __call__(self, x, y):\n",
    "        self.set_state()\n",
    "        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n",
    "                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n",
    "                else self.transform_coord(x,y))\n",
    "        return x, y\n",
    "\n",
    "    def transform_coord(self, x, y): return self.transform(x),y\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        x = self.do_transform(x,False)\n",
    "        return (x, self.do_transform(y,True)) if y is not None else x\n",
    "\n",
    "    @abstractmethod\n",
    "    def do_transform(self, x, is_y): raise NotImplementedError\n",
    "        \n",
    "        \n",
    "        \n",
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if is_y and self.tfm_y != TfmType.PIXEL: return x\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1/(c-1) if c<0 else c+1\n",
    "        x = lighting(x, b, c)\n",
    "        return x\n",
    "    \n",
    "class RandomDihedral(CoordTransform):\n",
    "    \"\"\"\n",
    "    Rotates images by random multiples of 90 degrees and/or reflection.\n",
    "    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n",
    "    \"\"\"\n",
    "    def set_state(self):\n",
    "        self.store.rot_times = random.randint(0,3)\n",
    "        self.store.do_flip = random.random()<0.5\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        x = np.rot90(x, self.store.rot_times)\n",
    "        return np.fliplr(x).copy() if self.store.do_flip else x\n",
    "    \n",
    "def rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotate an image by deg degrees\n",
    "\n",
    "    Arguments:\n",
    "        deg (float): degree to rotate.\n",
    "    \"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n",
    "\n",
    "class RandomRotate(CoordTransform):\n",
    "    \"\"\" Rotates images and (optionally) target y.\n",
    "\n",
    "    Rotating coordinates is treated differently for x and y on this\n",
    "    transform.\n",
    "     Arguments:\n",
    "        deg (float): degree to rotate.\n",
    "        p (float): probability of rotation\n",
    "        mode: type of border\n",
    "        tfm_y (TfmType): type of y transform\n",
    "    \"\"\"\n",
    "    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.deg,self.p = deg,p\n",
    "        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n",
    "            self.modes = (mode,cv2.BORDER_CONSTANT)\n",
    "        else:\n",
    "            self.modes = (mode,mode)\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.rdeg = rand0(self.deg)\n",
    "        self.store.rp = random.random()<self.p\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n",
    "                mode= self.modes[1] if is_y else self.modes[0],\n",
    "                interpolation=cv2.INTER_NEAREST)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def zoom_cv(x,z):\n",
    "    \"\"\" Zoom the center of image x by a factor of z+1 while retaining the original image size and proportion. \"\"\"\n",
    "    if z==0: return x\n",
    "    r,c,*_ = x.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n",
    "    return cv2.warpAffine(x,M,(c,r), borderMode=cv2.BORDER_CONSTANT, flags=cv2.WARP_FILL_OUTLIERS+cv2.INTER_NEAREST)\n",
    "\n",
    "class RandomZoom(CoordTransform):\n",
    "    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO, p=1):\n",
    "        super().__init__(tfm_y)\n",
    "        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n",
    "        self.p = p\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n",
    "        self.store.rp = random.random()<self.p\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        if self.store.rp:\n",
    "            x = zoom_cv(x, self.store.zoom)\n",
    "        return x\n",
    "    \n",
    "#RandomRotate(deg=30, p=0.7, tfm_y=TfmType.PIXEL)\n",
    "f = vgg16\n",
    "sz = 768\n",
    "tfms = tfms_from_model(f,\n",
    "                       sz,\n",
    "                       aug_tfms=[\n",
    "                                 RandomRotate(20, p=0.2, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.PIXEL),\n",
    "                       \n",
    "                                 RandomDihedral(tfm_y=TfmType.PIXEL),\n",
    "                           \n",
    "                                 RandomZoom(zoom_max=1.5, zoom_min=0, mode=cv2.BORDER_CONSTANT,\n",
    "                                            tfm_y=TfmType.PIXEL, p=0.2),\n",
    "                                 \n",
    "                                 RandomBlur(blur_strengths=3, probability=0.2, tfm_y=TfmType.NO),\n",
    "                                 \n",
    "                                 RandomLighting(0.05, 0.05)],\n",
    "                       \n",
    "                       tfm_y=TfmType.PIXEL,\n",
    "                       norm_y=False,\n",
    "                       crop_type=CropType.NO) \n",
    "\n",
    "\n",
    "dataset = ImageData.get_ds(FilesEncodedDataset, \n",
    "                           trn=(TRN_X, TRN_Y),\n",
    "                           val=(VAL_X, VAL_Y), tfms=tfms,\n",
    "                           test=None ,path=path)\n",
    "\n",
    "\n",
    "md = ImageData(path, dataset, bs=20, num_workers=8, classes=None)\n",
    "\n",
    "\n",
    "# load defined model# load  \n",
    "def get_encoder(f, cut):\n",
    "    base_model = (cut_model(f(True), cut))\n",
    "    return nn.Sequential(*base_model)\n",
    "\n",
    "def get_model(f=resnet18, sz=128):\n",
    "    \"\"\"gets dynamic unet model\"\"\"\n",
    "    # cut encoder\n",
    "    cut, cut_lr = model_meta[f]\n",
    "\n",
    "    # define encoder\n",
    "    encoder = get_encoder(f, cut)\n",
    "\n",
    "    # init model\n",
    "    # binary: ship - not ship\n",
    "    m = DynamicUnet(encoder, n_classes=1) \n",
    "\n",
    "    # init upsample on cpu\n",
    "    inp = torch.ones(1, 3, sz, sz)\n",
    "    out = m(V(inp).cpu())\n",
    "\n",
    "    # put model to gpu if desired# put mo \n",
    "    m = m.cuda(0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(logits, target):\n",
    "    logits = torch.sigmoid(logits)\n",
    "    smooth = 1.0\n",
    "\n",
    "    iflat = logits.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, logits, target):\n",
    "        logits = logits.squeeze(1)\n",
    "        if not (target.size() == logits.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), logits.size()))\n",
    "\n",
    "        max_val = (-logits).clamp(min=0)\n",
    "        loss = logits - logits * target + max_val + \\\n",
    "            ((-max_val).exp() + (-logits - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logits * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "class BCELoss2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCELoss2D, self).__init__()\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        logits = logits.squeeze(1)\n",
    "        logits = F.sigmoid(logits)\n",
    "        return F.binary_cross_entropy(logits, targets)\n",
    "\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()\n",
    "\n",
    "class UpsampleModel():\n",
    "    def __init__(self, model, cut_lr, name='upsample'):\n",
    "        self.model,self.name, self.cut_lr = model, name, cut_lr\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.encoder), [self.cut_lr]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = resnet18\n",
    "cut, cut_lr = model_meta[f]\n",
    "model = get_model(f, sz=768)\n",
    "models = UpsampleModel(model, cut_lr)\n",
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MixedLoss(10, 2)\n",
    "learn.metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f\"team_resnet18_fold_{FOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metric import sigmoid\n",
    "\n",
    "def flip(x, dim):\n",
    "    dim = x.dim() + dim if dim < 0 else dim\n",
    "    inds = tuple(slice(None, None) if i != dim\n",
    "             else x.new(torch.arange(x.size(i)-1, -1, -1).tolist()).long()\n",
    "             for i in range(x.dim()))\n",
    "    return x[inds]\n",
    "\n",
    "def tta_preds(x, model, mode=\"max\"):\n",
    "    out1 = to_np(model(V(x))) # original\n",
    "    out2 = to_np(model(V(torch.transpose(x,2,3).contiguous()))) # transpose\n",
    "    out3 = to_np(model(V(flip(x, 2)))) # flip dim=2 - y axis - updown\n",
    "    out4 = to_np(model(V(flip(x, 3)))) # flip dim=3 - x axis - left right\n",
    "    out5 = to_np(model(V(flip(flip(x, 2), 3)))) # flip dim=3 - x axis - updown left right\n",
    "    out6 = to_np(model(V(flip(torch.transpose(x,2,3).contiguous(), 3)))) # transpose left right\n",
    "    out7 = to_np(model(V(flip(torch.transpose(x,2,3).contiguous(), 2)))) # transpose up down\n",
    "    \n",
    "    \n",
    "    out1_probas = sigmoid(out1).squeeze(1) # original\n",
    "    out2_probas = sigmoid(out2).squeeze(1) # transpose\n",
    "    out3_probas = sigmoid(out3).squeeze(1) # flip dim=2 - y axis - updown\n",
    "    out4_probas = sigmoid(out4).squeeze(1) # flip dim=3 - x axis - left right\n",
    "    out5_probas = sigmoid(out5).squeeze(1)\n",
    "    out6_probas = sigmoid(out6).squeeze(1)\n",
    "    out7_probas = sigmoid(out7).squeeze(1)\n",
    "    \n",
    "    # reverse it\n",
    "    outs = []\n",
    "    for i, (out1_i, out2_i, out3_i, out4_i, out5_i, out6_i, out7_i) in enumerate(zip(out1_probas, out2_probas,\n",
    "                                                                      out3_probas, out4_probas,\n",
    "                                                                      out5_probas, out6_probas,\n",
    "                                                                      out7_probas)):\n",
    "        \n",
    "\n",
    "        if mode == \"max\":\n",
    "            outs.append(np.max([out1_i,\n",
    "                                out2_i.T,\n",
    "                                np.flipud(out3_i),\n",
    "                                np.fliplr(out4_i),\n",
    "                                np.fliplr(np.flipud(out5_i)),\n",
    "                                np.fliplr(out6_i).T,\n",
    "                                np.flipud(out7_i).T\n",
    "                               ], axis=0))\n",
    "        elif mode == \"mean\":\n",
    "            outs.append(np.mean([out1_i,\n",
    "                                 out2_i.T,\n",
    "                                 np.flipud(out3_i),\n",
    "                                 np.fliplr(out4_i),\n",
    "                                 np.fliplr(np.flipud(out5_i)),\n",
    "                                 np.fliplr(out6_i).T,\n",
    "                                 np.flipud(out7_i).T\n",
    "                                ], axis=0))\n",
    "        elif mode is None:\n",
    "            outs.append(out1_i)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "test_tta_preds = []\n",
    "for i, (x,y) in enumerate(learn.data.val_dl):\n",
    "    if i % 100 == 0: print(i)\n",
    "    test_tta_preds += tta_preds(x, model, mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [o.name for o in learn.data.val_ds.fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds_df = pd.DataFrame({\"fnames\":fnames, \"preds\":test_tta_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9711, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_preds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds_df.to_csv(path/f\"team_data/stacking/segmentation_fold_{FOLD}_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine fold preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds = []\n",
    "for FOLD in range(1,6):\n",
    "    df = pd.read_csv(path/f\"team_data/stacking/segmentation_fold_{FOLD}_preds.csv\")\n",
    "    fold_preds.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_fold_preds = pd.concat(fold_preds, 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
